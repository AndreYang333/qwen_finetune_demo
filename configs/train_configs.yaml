# configs/train_config.yaml
model_name_or_path: Qwen/Qwen-1.8B
lora: true  # true = LoRA 微调, false = 全量微调
output_dir: ./output_qwen

max_seq_length: 1024
train_batch_size: 1
eval_batch_size: 1
learning_rate: 2e-5
num_train_epochs: 3
logging_steps: 10
save_steps: 200
eval_steps: 200
warmup_ratio: 0.03

lora_config:
  r: 8
  lora_alpha: 32
  lora_dropout: 0.05
  bias: none
  task_type: CAUSAL_LM

data:
  train_file: ./data/train.jsonl
  val_file: null
