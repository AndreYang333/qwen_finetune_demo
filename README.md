# Qwen-1.8B å¾®è°ƒé¡¹ç›®ï¼ˆå…¨é‡å¾®è°ƒ + LoRAï¼‰

æœ¬é¡¹ç›®æä¾›åŸºäº [Qwen/Qwen-1.8B](https://huggingface.co/Qwen/Qwen-1.8B) çš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰è®­ç»ƒæ¡†æ¶ï¼Œæ”¯æŒ LoRA å¾®è°ƒ å’Œ å…¨é‡å¾®è°ƒ ä¸¤ç§æ–¹å¼ï¼Œé€‚é… HuggingFace Transformersï¼Œé€‚åˆè‡ªå®šä¹‰ä¸­æ–‡å¯¹è¯ä»»åŠ¡ã€‚

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
qwen_finetune_demo/
â”œâ”€â”€ configs/                  # è®­ç»ƒé…ç½®æ–‡ä»¶ï¼ˆæ”¯æŒ LoRA æ§åˆ¶ï¼‰
â”‚   â””â”€â”€ train_config.yaml
â”œâ”€â”€ data/                     # å¾®è°ƒæ•°æ®ï¼ˆprompt + response æ ¼å¼ï¼‰
â”‚   â”œâ”€â”€ train.jsonl
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ dataset.py            # è‡ªå®šä¹‰æ•°æ®åŠ è½½å™¨
â”‚   â””â”€â”€ trainer.py            # LoRA / å…¨é‡å¾®è°ƒé€»è¾‘
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_train.sh          # ä¸€é”®è®­ç»ƒè„šæœ¬ï¼ˆbashï¼‰
â”œâ”€â”€ prepare_data.py          # è‡ªåŠ¨ä¸‹è½½å¹¶è½¬æ¢æ•°æ®é›†ä¸º jsonl
â”œâ”€â”€ main.py                  # è®­ç»ƒä¸»å…¥å£
â”œâ”€â”€ requirements.txt         # æ‰€éœ€ä¾èµ–åŒ…
â””â”€â”€ README.md
```

---

## ğŸ”§ å®‰è£…ä¾èµ–

å»ºè®®ä½¿ç”¨ Python 3.10 + è™šæ‹Ÿç¯å¢ƒ + CUDA 11.7/12 ç¯å¢ƒï¼š

```bash
pip install -r requirements.txt
```

---

## ğŸ“¥ ä¸‹è½½å¹¶å‡†å¤‡æ•°æ®ï¼ˆHuggingFace æ ¼å¼ï¼‰

```bash
python prepare_data.py
```

æ•°æ®å°†ä¿å­˜ä¸ºï¼š`data/train.jsonl`ï¼Œæ¯æ¡æ ·æœ¬ä¸ºï¼š
```json
{"prompt": "è¯·åˆ†æä¸€ä¸‹è¿™å®¶å…¬å¸çš„è´¢æŠ¥ã€‚", "response": "æ ¹æ®æ•°æ®ï¼Œè¥æ”¶åŒæ¯”å¢é•¿10%ã€‚"}
```

---

## âš™ï¸ é…ç½®è®­ç»ƒå‚æ•°ï¼ˆconfigs/train_config.yamlï¼‰

```yaml
model_name_or_path: Qwen/Qwen-1.8B
lora: true            # true: ä½¿ç”¨LoRAå¾®è°ƒï¼›false: å…¨é‡å¾®è°ƒ
output_dir: ./output_qwen
train_batch_size: 1
learning_rate: 2e-5
...
```

---

## ğŸš€ å¼€å§‹è®­ç»ƒ

```bash
python main.py
```

æˆ–è€…ä½¿ç”¨è„šæœ¬ï¼š
```bash
bash scripts/run_train.sh
```

è®­ç»ƒä¸­é—´ç»“æœå’Œæœ€ç»ˆæ¨¡å‹å°†ä¿å­˜åœ¨ `output_qwen/` ä¸­ã€‚

---

## ğŸ§  æ”¯æŒåŠŸèƒ½
- âœ… LoRA å¾®è°ƒï¼ˆå†…ç½® peft æ”¯æŒï¼‰
- âœ… å…¨é‡å¾®è°ƒ
- âœ… å¯æ›¿æ¢ HuggingFace è‡ªå®šä¹‰æ•°æ®é›†
- âœ… é…ç½®çµæ´»ï¼ˆYAML é…ç½®ï¼‰

---

## ğŸ”® æ¨ç†ï¼ˆç¤ºä¾‹ï¼‰

åç»­å¯æ·»åŠ  `inference.py`ï¼Œç”¨äºåŠ è½½æ¨¡å‹å’Œç”Ÿæˆå›ç­”ã€‚

---

## ğŸ“Œ æ•°æ®æ ¼å¼è¦æ±‚ï¼ˆå…¼å®¹ Alpaca æ ¼å¼ï¼‰

```json
{"instruction": "è¯·å›ç­”ä»¥ä¸‹è´¢åŠ¡é—®é¢˜ã€‚", "input": "æŸå…¬å¸å‡€åˆ©æ¶¦å¢é•¿ä¸ºè´Ÿï¼ŒåŸå› å¯èƒ½æ˜¯ä»€ä¹ˆï¼Ÿ", "output": "å¯èƒ½æ˜¯è¥ä¸šæ”¶å…¥ä¸‹é™æˆ–æˆæœ¬ä¸Šå‡æ‰€è‡´ã€‚"}
```

ä½¿ç”¨ `prepare_data.py` ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ã€‚

---

## ğŸ“ è‡´è°¢
- [Qwen](https://huggingface.co/Qwen) æ¨¡å‹æä¾›æ”¯æŒ
- [HuggingFace Datasets](https://huggingface.co/datasets) æ•°æ®æ¥å£
- [PEFT](https://github.com/huggingface/peft) LoRA æ”¯æŒåº“
